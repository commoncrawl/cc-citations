@Article{cc:ChibaNakanoKoide:2025:DomainHarvester,
  author       = "Chiba, Daiki and Nakano, Hiroki and Koide, Takashi",
  journal      = "IEEE Access",
  title        = "DomainHarvester: Uncovering Trustworthy Domains Beyond Popularity Rankings",
  year         = "2025",
  volume       = "13",
  pages        = "28167--28188",
  keywords     = "Virtual assistants;Accuracy;Feature extraction;Domain Name System;Accesslists;Uniform resource
                 locators;Reliability;Postal services;Message authentication;Measurement;Web security;domain name;top
                 list;allow list",
  doi          = "10.1109/ACCESS.2025.3539882",
  URL          = "https://ieeexplore.ieee.org/abstract/document/10877793",
  abstract     = "Allow lists are crucial in cybersecurity for distinguishing safe websites from potential threats.
                 Traditional approaches relying on website popularity often fail to capture trustworthy but less-visited
                 domains, leading to increased false positives and overlooked niche websites. This paper presents
                 DomainHarvester, an innovative bottom-up system that leverages the web’s hyperlink structure and a
                 Transformer-based machine learning approach to systematically identify and include these
                 underrepresented yet legitimate domains. Results demonstrate how DomainHarvester dynamically curates an
                 expanded allow list (DHList), substantially reducing the risk of false positives while retaining high
                 precision in excluding malicious sites. Comprehensive evaluations and a real-world case study with a
                 managed security services provider illustrate the efficacy and practicality of this approach. By
                 integrating DomainHarvester, organizations and researchers can benefit from a more inclusive and
                 globally representative cybersecurity allow list, addressing limitations in existing top-list-based
                 solutions.",
  cc-author-affiliation = "NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan",
  cc-class     = "web-science, domain-ranking, internet-security, cc-citet-not-used",
  cc-snippet   = "Top lists serve a variety of purposes across many services. [...] They serve as data sources for web
                 crawling in projects like Common Crawl [39] [³⁹Common Crawl, ‘‘Common Crawl - Open Repository of
                 Web Crawl Data,’’ 2024. [Online]. Available: https://commoncrawl.org/], which provides data for AI
                 training, including models like ChatGPT.",
}

@Misc{cc:HosseinbeigiTaherinezhadFailiBaghbaniEtAl:2025:Matina,
  title        = "Matina: {A} Large-Scale 73{B} Token Persian Text Corpus",
  author       = "Sara Bourbour Hosseinbeigi and Fatemeh Taherinezhad and Heshaam Faili and Hamed Baghbani and Fatemeh
                 Nadi and Mostafa Amiri",
  year         = "2025",
  eprint       = "2502.09188",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2502.09188",
  pdf          = "https://arxiv.org/pdf/2502.09188",
  cc-author-affiliation = "Tarbiat Modares University, Iran; University of Tehran, Iran",
  cc-class     = "nlp/corpus-construction, nlp/language-specific-corpus, nlp/language-model, nlp/large-language-models",
  abstract     = "Text corpora are essential for training models used in tasks like summarization, translation, and
                 large language models (LLMs). While various efforts have been made to collect monolingual and
                 multilingual datasets in many languages, Persian has often been underrepresented due to limited
                 resources for data collection and preprocessing. Existing Persian datasets are typically small and lack
                 content diversity, consisting mainly of weblogs and news articles. This shortage of high-quality,
                 varied data has slowed the development of NLP models and open-source LLMs for Persian. Since model
                 performance depends heavily on the quality of training data, we address this gap by introducing the
                 Matina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed and deduplicated to ensure
                 high data quality. We further assess its effectiveness by training and evaluating transformer-based
                 models on key NLP tasks. Both the dataset and preprocessing codes are publicly available, enabling
                 researchers to build on and improve this resource for future Persian NLP advancements.",
  cc-snippet   = "Matina’s web-based data is divided into two parts: data crawled by our team and data taken from two
                 public databases using the Common Crawl (Crawl, 2008) dataset. This dual-source strategy uses both
                 proprietary and publically available data to increase the corpus’s breadth and diversity. In any
                 language, certain domains are recognized for their reliability and high-quality information. We
                 identified such domains in Persian and crawled them to extract relevant textual content. This step
                 helped minimize the inclusion of irrelevant ele- ments such as advertisements, tags, or comments. Text
                 extracted from headings and paragraphs was merged to form unified documents, with additional
                 informative fields (e.g., summaries or subheadings) incorporated as metadata, if available. Because
                 these domains were manually selected, language detection and URL filtering were unnecessary. We also
                 ensured that the selected URLs did not contain harmful, sensitive, or adult content.",
}

@Misc{cc:KoenigRauchWoerter:2025:Monitoring-of-economic-shocks,
  title        = "Real-time Monitoring of Economic Shocks using Company Websites",
  author       = "Michael Koenig and Jakob Rauch and Martin Woerter",
  year         = "2025",
  eprint       = "2502.17161",
  archiveprefix = "arXiv",
  primaryclass = "econ.GN",
  keywords     = "large language models, natural language processing, crisis, economic shocks, economic monitoring,
                 Covid-19",
  URL          = "https://arxiv.org/abs/2502.17161",
  abstract     = "Understanding the effects of economic shocks on firms is critical for analyzing economic growth and
                 resilience. We introduce a Web-Based Affectedness Indicator (WAI), a general-purpose tool for real-time
                 monitoring of economic disruptions across diverse contexts. By leveraging Large Language Model (LLM)
                 assisted classification and information extraction on texts from over five million company websites,
                 WAI quantifies the degree and nature of firms' responses to external shocks. Using the COVID-19
                 pandemic as a specific application, we show that WAI is highly correlated with pandemic containment
                 measures and reliably predicts firm performance. Unlike traditional data sources, WAI provides timely
                 firm-level information across industries and geographies worldwide that would otherwise be unavailable
                 due to institutional and data availability constraints. This methodology offers significant potential
                 for monitoring and mitigating the impact of technological, political, financial, health or
                 environmental crises, and represents a transformative tool for adaptive policy-making and economic
                 resilience.",
  cc-author-affiliation = "ETH Zurich, Switzerland; Vrije Universiteit Amsterdam, The Netherlands; Centre for Economic
                 Policy Research (CEPR), London, United Kingdom",
  cc-class     = "economics, economic-monitoring, web-archiving, nlp/large-language-models",
  cc-snippet   = "We extract content from company websites in CommonCrawl, classify Covid-19 impact using a large
                 language model, and track changes over time to analyze firm-level impacts across sectors and different
                 geographies.",
}

@Misc{cc:FiazTahirShamsHussain:2025:UrduLLaMA-1.0-dataset,
  title        = "Urdu{LL}a{MA} 1.0: Dataset Curation, Preprocessing, and Evaluation in Low-Resource Settings",
  author       = "Layba Fiaz and Munief Hassan Tahir and Sana Shams and Sarmad Hussain",
  year         = "2025",
  eprint       = "2502.16961",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2502.16961",
  cc-author-affiliation = "University of Engineering and Technology, Lahore, Pakistan",
  cc-class     = "nlp/language-model, nlp/text-corpora, nlp/low-resource-language",
  cc-derived-dataset-used = "CC-100, OSCAR",
  cc-snippet   = "[...] we supplemented our in-house dataset with data from several publicly available sources,
                 including CC-100 (Wenzek et al., 2020), the Urdu corpus from OSCAR (Ortiz Suárez et al., 2020), the
                 Urdu Web Corpus (Shafiq et al., 2020), Urdu data from XLSum (Hasan et al., 2021), and (Goldhahn et al.,
                 2012).",
}

@Misc{cc:LongpreSinghCherepTiwaryEtAl:2025:Data-provenance-gap,
  title        = "Bridging the Data Provenance Gap Across Text, Speech and Video",
  author       = "Shayne Longpre and Nikhil Singh and Manuel Cherep and Kushagra Tiwary and Joanna Materzynska and
                 William Brannon and Robert Mahari and Naana Obeng-Marnu and Manan Dey and Mohammed Hamdy and Nayan
                 Saxena and Ahmad Mustafa Anis and Emad A. Alghamdi and Vu Minh Chien and Da Yin and Kun Qian and Yizhi
                 Li and Minnie Liang and An Dinh and Shrestha Mohanty and Deividas Mataciunas and Tobin South and
                 Jianguo Zhang and Ariel N. Lee and Campbell S. Lund and Christopher Klamm and Damien Sileo and Diganta
                 Misra and Enrico Shippole and Kevin Klyman and Lester JV Miranda and Niklas Muennighoff and Seonghyeon
                 Ye and Seungone Kim and Vipul Gupta and Vivek Sharma and Xuhui Zhou and Caiming Xiong and Luis Villa
                 and Stella Biderman and Alex Pentland and Sara Hooker and Jad Kabbara",
  year         = "2025",
  eprint       = "2412.17847",
  archiveprefix = "arXiv",
  primaryclass = "cs.AI",
  URL          = "https://arxiv.org/abs/2412.17847",
  cc-author-affiliation = "The Data Provenance Initiative",
  cc-class     = "dataset-creation, dataset-curation, data-provenance, cc-not-used, cc-not-cited",
}

@Misc{cc:YuLiuXiong:2025:Craw4LLM-Efficient-Web-Crawling,
  title        = "Craw4{LLM}: Efficient Web Crawling for {LLM} Pretraining",
  author       = "Shi Yu and Zhiyuan Liu and Chenyan Xiong",
  year         = "2025",
  eprint       = "2502.13347",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2502.13347",
  cc-author-affiliation = "Tsinghua University, China; Carnegie Mellon University, USA",
  cc-class     = "web-crawling, nlp/web-as-corpus, nlp/text-corpora, nlp/large-language-models, cc-cited-not-used",
  cc-snippet   = "Pretraining datasets are typically built from large-scale web crawls such as Common Crawl
                 (CommonCrawl, 2007), which may contain TBs of data spanning billions of web- pages (Penedo et al.,
                 2024; Weber et al., 2024). [...] Existing work often discards over 90% of the raw data collected from
                 the web (Li et al., 2024; Penedo et al., 2024; Tang et al., 2024) highlighting the inefficiency of
                 current web crawlers in collecting LLM pretraining data. Common web crawlers like Common Crawl
                 prioritize pages based on graph connectivity metrics like PageRank (Page et al., 1999; Cho et al.,
                 1998) or harmonic centrality (Boldi and Vigna, 2014; Baack, 2024), which favor documents with a high
                 number of inlinks (indegree) (Fortunato et al., 2008) rather than those most relevant for pretraining.
                 This misalignment not only leads to waste in computational resources during excessive data processing
                 for LLM developers, but also incentivizes over-crawling, which burdens website operators with redundant
                 traffic and increases ethical and legal risks related to fair use of data and copyright (Longpre et
                 al., 2024; New York Times, 2023). [...] CRAW4LLM achieves the same performance while crawling only 21%
                 of the documents required by the indegree-based crawler, or 48% when considering all visited documents.
                 These results highlight the efficiency of CRAW4LLM, demonstrating its potential to reduce website
                 burdens and mitigate over-crawling.",
}

@Misc{cc:BaackBidermanOdrozekSkowronEtAl:2025:Open-datasets-for-LLM-training,
  title        = "Towards Best Practices for Open Datasets for {LLM} Training",
  author       = "Stefan Baack and Stella Biderman and Kasia Odrozek and Aviya Skowron and Ayah Bdeir and Jillian
                 Bommarito and Jennifer Ding and Maximilian Gahntz and Paul Keller and Pierre-Carl Langlais and Greg
                 Lindahl and Sebastian Majstorovic and Nik Marda and Guilherme Penedo and Maarten Van Segbroeck and
                 Jennifer Wang and Leandro von Werra and Mitchell Baker and Julie Belião and Kasia Chmielinski and
                 Marzieh Fadaee and Lisa Gutermuth and Hynek Kydlíček and Greg Leppert and EM Lewis-Jong and Solana
                 Larsen and Shayne Longpre and Angela Oduor Lungati and Cullen Miller and Victor Miller and Max Ryabinin
                 and Kathleen Siminyu and Andrew Strait and Mark Surman and Anna Tumadóttir and Maurice Weber and
                 Rebecca Weiss and Lee White and Thomas Wolf",
  year         = "2025",
  eprint       = "2501.08365",
  archiveprefix = "arXiv",
  primaryclass = "cs.CY",
  URL          = "https://arxiv.org/abs/2501.08365",
  cc-author-affiliation = "",
  cc-class     = "dataset-creation, dataset-curation, data-provenance, license/creative-commons, license/public-domain",
  abstract     = "Many AI companies are training their large language models (LLMs) on data without the permission of
                 the copyright owners. The permissibility of doing so varies by jurisdiction: in countries like the EU
                 and Japan, this is allowed under certain restrictions, while in the United States, the legal landscape
                 is more ambiguous. Regardless of the legal status, concerns from creative producers have led to several
                 high-profile copyright lawsuits, and the threat of litigation is commonly cited as a reason for the
                 recent trend towards minimizing the information shared about training datasets by both corporate and
                 public interest actors. This trend in limiting data information causes harm by hindering transparency,
                 accountability, and innovation in the broader ecosystem by denying researchers, auditors, and impacted
                 individuals access to the information needed to understand AI models. While this could be mitigated by
                 training language models on open access and public domain data, at the time of writing, there are no
                 such models (trained at a meaningful scale) due to the substantial technical and sociological
                 challenges in assembling the necessary corpus. These challenges include incomplete and unreliable
                 metadata, the cost and complexity of digitizing physical records, and the diverse set of legal and
                 technical skills required to ensure relevance and responsibility in a quickly changing landscape.
                 Building towards a future where AI systems can be trained on openly licensed data that is responsibly
                 curated and governed requires collaboration across legal, technical, and policy domains, along with
                 investments in metadata standards, digitization, and fostering a culture of openness.",
  cc-derived-dataset-about = "Common-Pile",
}

@Misc{cc:ChangHe:2025:Liabilities-of-Robotstxt,
  title        = "The Liabilities of Robots.txt",
  author       = "Chien-yi Chang and Xin He",
  year         = "2025",
  eprint       = "2503.06035",
  archiveprefix = "arXiv",
  primaryclass = "cs.CY",
  URL          = "https://arxiv.org/abs/2503.06035",
  abstract     = "The robots.txt file, introduced as part of the Robots Exclusion Protocol in 1994, provides webmasters
                 with a mechanism to communicate access permissions to automated bots. While broadly adopted as a
                 community standard, the legal liabilities associated with violating robots.txt remain ambiguous. The
                 rapid rise of large language models, which depend on extensive datasets for training, has amplified
                 these challenges, prompting webmasters to increasingly use robots.txt to restrict the activities of
                 bots engaged in large-scale data collection. This paper clarifies the liabilities associated with
                 robots.txt within the contexts of contract, copyright, and tort law. Drawing on key cases, legal
                 principles, and scholarly discourse, it proposes a legal framework for web scraping disputes. It also
                 addresses the growing fragmentation of the internet, as restrictive practices by webmasters threaten
                 the principles of openness and collaboration. Through balancing innovation with accountability, this
                 paper offers insights to ensure that robots.txt remains an equitable protocol for the internet and thus
                 contributes to digital governance in the age of AI.",
  cc-author-affiliation = "Faculty of Law, University of Hong Kong, Hong Kong SAR",
  cc-class     = "robots.txt, web-crawling, legal/copyright, ai/ethics-of-machine-learning",
}

@Article{cc:KimSohnJoChoiEtAl:2025:Do-not-trust-licenses-you-see,
  title        = "Do Not Trust Licenses You See--Dataset Compliance Requires Massive-Scale {AI}-Powered Lifecycle
                 Tracing",
  author       = "Kim, Jaekyeom and Sohn, Sungryull and Jo, Gerrard Jeongwon and Choi, Jihoon and Bae, Kyunghoon and
                 Lee, Hwayoung and Park, Yongmin and Lee, Honglak",
  journal      = "arXiv preprint arXiv:2503.02784",
  year         = "2025",
  URL          = "https://arxiv.org/abs/2503.02784",
  pdf          = "https://asset-nexus.lgresearch.ai/pdf/Do_Not_Trust_Licenses_You_See.pdf",
  abstract     = "This paper argues that a dataset's legal risk cannot be accurately assessed by its license terms
                 alone; instead, tracking dataset redistribution and its full lifecycle is essential. However, this
                 process is too complex for legal experts to handle manually at scale. Tracking dataset provenance,
                 verifying redistribution rights, and assessing evolving legal risks across multiple stages require a
                 level of precision and efficiency that exceeds human capabilities. Addressing this challenge
                 effectively demands AI agents that can systematically trace dataset redistribution, analyze compliance,
                 and identify legal risks. We develop an automated data compliance system called NEXUS and show that AI
                 can perform these tasks with higher accuracy, efficiency, and cost-effectiveness than human experts.
                 Our massive legal analysis of 17,429 unique entities and 8,072 license terms using this approach
                 reveals the discrepancies in legal rights between the original datasets before redistribution and their
                 redistributed subsets, underscoring the necessity of the data lifecycle-aware compliance. For instance,
                 we find that out of 2,852 datasets with commercially viable individual license terms, only 605 (21\%)
                 are legally permissible for commercialization. This work sets a new standard for AI data governance,
                 advocating for a framework that systematically examines the entire lifecycle of dataset redistribution
                 to ensure transparent, legal, and responsible dataset management.",
  cc-author-affiliation = "LG AI Research",
  cc-class     = "legal/copyright, ai/ethics-of-machine-learning, robots.txt, web-crawling",
}
 
