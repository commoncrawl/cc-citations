@Article{cc:ChibaNakanoKoide:2025:DomainHarvester,
  author       = "Chiba, Daiki and Nakano, Hiroki and Koide, Takashi",
  journal      = "IEEE Access",
  title        = "DomainHarvester: Uncovering Trustworthy Domains Beyond Popularity Rankings",
  year         = "2025",
  volume       = "13",
  pages        = "28167--28188",
  keywords     = "Virtual assistants;Accuracy;Feature extraction;Domain Name System;Accesslists;Uniform resource
                 locators;Reliability;Postal services;Message authentication;Measurement;Web security;domain name;top
                 list;allow list",
  doi          = "10.1109/ACCESS.2025.3539882",
  URL          = "https://ieeexplore.ieee.org/abstract/document/10877793",
  abstract     = "Allow lists are crucial in cybersecurity for distinguishing safe websites from potential threats.
                 Traditional approaches relying on website popularity often fail to capture trustworthy but less-visited
                 domains, leading to increased false positives and overlooked niche websites. This paper presents
                 DomainHarvester, an innovative bottom-up system that leverages the web’s hyperlink structure and a
                 Transformer-based machine learning approach to systematically identify and include these
                 underrepresented yet legitimate domains. Results demonstrate how DomainHarvester dynamically curates an
                 expanded allow list (DHList), substantially reducing the risk of false positives while retaining high
                 precision in excluding malicious sites. Comprehensive evaluations and a real-world case study with a
                 managed security services provider illustrate the efficacy and practicality of this approach. By
                 integrating DomainHarvester, organizations and researchers can benefit from a more inclusive and
                 globally representative cybersecurity allow list, addressing limitations in existing top-list-based
                 solutions.",
  cc-author-affiliation = "NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan",
  cc-class     = "web-science, domain-ranking, internet-security, cc-citet-not-used",
  cc-snippet   = "Top lists serve a variety of purposes across many services. [...] They serve as data sources for web
                 crawling in projects like Common Crawl [39] [³⁹Common Crawl, ‘‘Common Crawl - Open Repository of
                 Web Crawl Data,’’ 2024. [Online]. Available: https://commoncrawl.org/], which provides data for AI
                 training, including models like ChatGPT.",
}

@Misc{cc:HosseinbeigiTaherinezhadFailiBaghbaniEtAl:2025:Matina,
  title        = "Matina: {A} Large-Scale 73{B} Token Persian Text Corpus",
  author       = "Sara Bourbour Hosseinbeigi and Fatemeh Taherinezhad and Heshaam Faili and Hamed Baghbani and Fatemeh
                 Nadi and Mostafa Amiri",
  year         = "2025",
  eprint       = "2502.09188",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2502.09188",
  pdf          = "https://arxiv.org/pdf/2502.09188",
  cc-author-affiliation = "Tarbiat Modares University, Iran; University of Tehran, Iran",
  cc-class     = "nlp/corpus-construction, nlp/language-specific-corpus, nlp/language-model, nlp/large-language-models",
  abstract     = "Text corpora are essential for training models used in tasks like summarization, translation, and
                 large language models (LLMs). While various efforts have been made to collect monolingual and
                 multilingual datasets in many languages, Persian has often been underrepresented due to limited
                 resources for data collection and preprocessing. Existing Persian datasets are typically small and lack
                 content diversity, consisting mainly of weblogs and news articles. This shortage of high-quality,
                 varied data has slowed the development of NLP models and open-source LLMs for Persian. Since model
                 performance depends heavily on the quality of training data, we address this gap by introducing the
                 Matina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed and deduplicated to ensure
                 high data quality. We further assess its effectiveness by training and evaluating transformer-based
                 models on key NLP tasks. Both the dataset and preprocessing codes are publicly available, enabling
                 researchers to build on and improve this resource for future Persian NLP advancements.",
  cc-snippet   = "Matina’s web-based data is divided into two parts: data crawled by our team and data taken from two
                 public databases using the Common Crawl (Crawl, 2008) dataset. This dual-source strategy uses both
                 proprietary and publically available data to increase the corpus’s breadth and diversity. In any
                 language, certain domains are recognized for their reliability and high-quality information. We
                 identified such domains in Persian and crawled them to extract relevant textual content. This step
                 helped minimize the inclusion of irrelevant elements such as advertisements, tags, or comments. Text
                 extracted from headings and paragraphs was merged to form unified documents, with additional
                 informative fields (e.g., summaries or subheadings) incorporated as metadata, if available. Because
                 these domains were manually selected, language detection and URL filtering were unnecessary. We also
                 ensured that the selected URLs did not contain harmful, sensitive, or adult content.",
}

@Misc{cc:KoenigRauchWoerter:2025:Monitoring-of-economic-shocks,
  title        = "Real-time Monitoring of Economic Shocks using Company Websites",
  author       = "Michael Koenig and Jakob Rauch and Martin Woerter",
  year         = "2025",
  eprint       = "2502.17161",
  archiveprefix = "arXiv",
  primaryclass = "econ.GN",
  keywords     = "large language models, natural language processing, crisis, economic shocks, economic monitoring,
                 Covid-19",
  URL          = "https://arxiv.org/abs/2502.17161",
  abstract     = "Understanding the effects of economic shocks on firms is critical for analyzing economic growth and
                 resilience. We introduce a Web-Based Affectedness Indicator (WAI), a general-purpose tool for real-time
                 monitoring of economic disruptions across diverse contexts. By leveraging Large Language Model (LLM)
                 assisted classification and information extraction on texts from over five million company websites,
                 WAI quantifies the degree and nature of firms' responses to external shocks. Using the COVID-19
                 pandemic as a specific application, we show that WAI is highly correlated with pandemic containment
                 measures and reliably predicts firm performance. Unlike traditional data sources, WAI provides timely
                 firm-level information across industries and geographies worldwide that would otherwise be unavailable
                 due to institutional and data availability constraints. This methodology offers significant potential
                 for monitoring and mitigating the impact of technological, political, financial, health or
                 environmental crises, and represents a transformative tool for adaptive policy-making and economic
                 resilience.",
  cc-author-affiliation = "ETH Zurich, Switzerland; Vrije Universiteit Amsterdam, The Netherlands; Centre for Economic
                 Policy Research (CEPR), London, United Kingdom",
  cc-class     = "economics, economic-monitoring, web-archiving, nlp/large-language-models",
  cc-snippet   = "We extract content from company websites in CommonCrawl, classify Covid-19 impact using a large
                 language model, and track changes over time to analyze firm-level impacts across sectors and different
                 geographies.",
}

@Misc{cc:FiazTahirShamsHussain:2025:UrduLLaMA-1.0-dataset,
  title        = "Urdu{LL}a{MA} 1.0: Dataset Curation, Preprocessing, and Evaluation in Low-Resource Settings",
  author       = "Layba Fiaz and Munief Hassan Tahir and Sana Shams and Sarmad Hussain",
  year         = "2025",
  eprint       = "2502.16961",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2502.16961",
  cc-author-affiliation = "University of Engineering and Technology, Lahore, Pakistan",
  cc-class     = "nlp/language-model, nlp/text-corpora, nlp/low-resource-language",
  cc-derived-dataset-used = "CC-100, OSCAR",
  cc-snippet   = "[...] we supplemented our in-house dataset with data from several publicly available sources,
                 including CC-100 (Wenzek et al., 2020), the Urdu corpus from OSCAR (Ortiz Suárez et al., 2020), the
                 Urdu Web Corpus (Shafiq et al., 2020), Urdu data from XLSum (Hasan et al., 2021), and (Goldhahn et al.,
                 2012).",
}

@Misc{cc:LongpreSinghCherepTiwaryEtAl:2025:Data-provenance-gap,
  title        = "Bridging the Data Provenance Gap Across Text, Speech and Video",
  author       = "Shayne Longpre and Nikhil Singh and Manuel Cherep and Kushagra Tiwary and Joanna Materzynska and
                 William Brannon and Robert Mahari and Naana Obeng-Marnu and Manan Dey and Mohammed Hamdy and Nayan
                 Saxena and Ahmad Mustafa Anis and Emad A. Alghamdi and Vu Minh Chien and Da Yin and Kun Qian and Yizhi
                 Li and Minnie Liang and An Dinh and Shrestha Mohanty and Deividas Mataciunas and Tobin South and
                 Jianguo Zhang and Ariel N. Lee and Campbell S. Lund and Christopher Klamm and Damien Sileo and Diganta
                 Misra and Enrico Shippole and Kevin Klyman and Lester JV Miranda and Niklas Muennighoff and Seonghyeon
                 Ye and Seungone Kim and Vipul Gupta and Vivek Sharma and Xuhui Zhou and Caiming Xiong and Luis Villa
                 and Stella Biderman and Alex Pentland and Sara Hooker and Jad Kabbara",
  year         = "2025",
  eprint       = "2412.17847",
  archiveprefix = "arXiv",
  primaryclass = "cs.AI",
  URL          = "https://arxiv.org/abs/2412.17847",
  cc-author-affiliation = "The Data Provenance Initiative",
  cc-class     = "dataset-creation, dataset-curation, data-provenance, cc-not-used, cc-not-cited",
}

@Misc{cc:YuLiuXiong:2025:Craw4LLM-Efficient-Web-Crawling,
  title        = "Craw4{LLM}: Efficient Web Crawling for {LLM} Pretraining",
  author       = "Shi Yu and Zhiyuan Liu and Chenyan Xiong",
  year         = "2025",
  eprint       = "2502.13347",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2502.13347",
  cc-author-affiliation = "Tsinghua University, China; Carnegie Mellon University, USA",
  cc-class     = "web-crawling, nlp/web-as-corpus, nlp/text-corpora, nlp/large-language-models, cc-cited-not-used",
  cc-snippet   = "Pretraining datasets are typically built from large-scale web crawls such as Common Crawl
                 (CommonCrawl, 2007), which may contain TBs of data spanning billions of web-pages (Penedo et al., 2024;
                 Weber et al., 2024). [...] Existing work often discards over 90\% of the raw data collected from the
                 web (Li et al., 2024; Penedo et al., 2024; Tang et al., 2024) highlighting the inefficiency of current
                 web crawlers in collecting LLM pretraining data. Common web crawlers like Common Crawl prioritize pages
                 based on graph connectivity metrics like PageRank (Page et al., 1999; Cho et al., 1998) or harmonic
                 centrality (Boldi and Vigna, 2014; Baack, 2024), which favor documents with a high number of inlinks
                 (indegree) (Fortunato et al., 2008) rather than those most relevant for pretraining. This misalignment
                 not only leads to waste in computational resources during excessive data processing for LLM developers,
                 but also incentivizes over-crawling, which burdens website operators with redundant traffic and
                 increases ethical and legal risks related to fair use of data and copyright (Longpre et al., 2024; New
                 York Times, 2023). [...] CRAW4LLM achieves the same performance while crawling only 21\% of the
                 documents required by the indegree-based crawler, or 48\% when considering all visited documents. These
                 results highlight the efficiency of CRAW4LLM, demonstrating its potential to reduce website burdens and
                 mitigate over-crawling.",
}

@Misc{cc:BaackBidermanOdrozekSkowronEtAl:2025:Open-datasets-for-LLM-training,
  title        = "Towards Best Practices for Open Datasets for {LLM} Training",
  author       = "Stefan Baack and Stella Biderman and Kasia Odrozek and Aviya Skowron and Ayah Bdeir and Jillian
                 Bommarito and Jennifer Ding and Maximilian Gahntz and Paul Keller and Pierre-Carl Langlais and Greg
                 Lindahl and Sebastian Majstorovic and Nik Marda and Guilherme Penedo and Maarten Van Segbroeck and
                 Jennifer Wang and Leandro von Werra and Mitchell Baker and Julie Belião and Kasia Chmielinski and
                 Marzieh Fadaee and Lisa Gutermuth and Hynek Kydlíček and Greg Leppert and EM Lewis-Jong and Solana
                 Larsen and Shayne Longpre and Angela Oduor Lungati and Cullen Miller and Victor Miller and Max Ryabinin
                 and Kathleen Siminyu and Andrew Strait and Mark Surman and Anna Tumadóttir and Maurice Weber and
                 Rebecca Weiss and Lee White and Thomas Wolf",
  year         = "2025",
  eprint       = "2501.08365",
  archiveprefix = "arXiv",
  primaryclass = "cs.CY",
  URL          = "https://arxiv.org/abs/2501.08365",
  cc-author-affiliation = "",
  cc-class     = "dataset-creation, dataset-curation, data-provenance, license/creative-commons, license/public-domain",
  abstract     = "Many AI companies are training their large language models (LLMs) on data without the permission of
                 the copyright owners. The permissibility of doing so varies by jurisdiction: in countries like the EU
                 and Japan, this is allowed under certain restrictions, while in the United States, the legal landscape
                 is more ambiguous. Regardless of the legal status, concerns from creative producers have led to several
                 high-profile copyright lawsuits, and the threat of litigation is commonly cited as a reason for the
                 recent trend towards minimizing the information shared about training datasets by both corporate and
                 public interest actors. This trend in limiting data information causes harm by hindering transparency,
                 accountability, and innovation in the broader ecosystem by denying researchers, auditors, and impacted
                 individuals access to the information needed to understand AI models. While this could be mitigated by
                 training language models on open access and public domain data, at the time of writing, there are no
                 such models (trained at a meaningful scale) due to the substantial technical and sociological
                 challenges in assembling the necessary corpus. These challenges include incomplete and unreliable
                 metadata, the cost and complexity of digitizing physical records, and the diverse set of legal and
                 technical skills required to ensure relevance and responsibility in a quickly changing landscape.
                 Building towards a future where AI systems can be trained on openly licensed data that is responsibly
                 curated and governed requires collaboration across legal, technical, and policy domains, along with
                 investments in metadata standards, digitization, and fostering a culture of openness.",
  cc-derived-dataset-about = "Common-Pile",
}

@Misc{cc:ChangHe:2025:Liabilities-of-Robotstxt,
  title        = "The Liabilities of Robots.txt",
  author       = "Chien-yi Chang and Xin He",
  year         = "2025",
  eprint       = "2503.06035",
  archiveprefix = "arXiv",
  primaryclass = "cs.CY",
  URL          = "https://arxiv.org/abs/2503.06035",
  abstract     = "The robots.txt file, introduced as part of the Robots Exclusion Protocol in 1994, provides webmasters
                 with a mechanism to communicate access permissions to automated bots. While broadly adopted as a
                 community standard, the legal liabilities associated with violating robots.txt remain ambiguous. The
                 rapid rise of large language models, which depend on extensive datasets for training, has amplified
                 these challenges, prompting webmasters to increasingly use robots.txt to restrict the activities of
                 bots engaged in large-scale data collection. This paper clarifies the liabilities associated with
                 robots.txt within the contexts of contract, copyright, and tort law. Drawing on key cases, legal
                 principles, and scholarly discourse, it proposes a legal framework for web scraping disputes. It also
                 addresses the growing fragmentation of the internet, as restrictive practices by webmasters threaten
                 the principles of openness and collaboration. Through balancing innovation with accountability, this
                 paper offers insights to ensure that robots.txt remains an equitable protocol for the internet and thus
                 contributes to digital governance in the age of AI.",
  cc-author-affiliation = "Faculty of Law, University of Hong Kong, Hong Kong SAR",
  cc-class     = "robots.txt, web-crawling, legal/copyright, ai/ethics-of-machine-learning",
}

@Article{cc:KimSohnJoChoiEtAl:2025:Do-not-trust-licenses-you-see,
  title        = "Do Not Trust Licenses You See--Dataset Compliance Requires Massive-Scale {AI}-Powered Lifecycle
                 Tracing",
  author       = "Kim, Jaekyeom and Sohn, Sungryull and Jo, Gerrard Jeongwon and Choi, Jihoon and Bae, Kyunghoon and
                 Lee, Hwayoung and Park, Yongmin and Lee, Honglak",
  journal      = "arXiv preprint arXiv:2503.02784",
  year         = "2025",
  URL          = "https://arxiv.org/abs/2503.02784",
  pdf          = "https://asset-nexus.lgresearch.ai/pdf/Do_Not_Trust_Licenses_You_See.pdf",
  abstract     = "This paper argues that a dataset's legal risk cannot be accurately assessed by its license terms
                 alone; instead, tracking dataset redistribution and its full lifecycle is essential. However, this
                 process is too complex for legal experts to handle manually at scale. Tracking dataset provenance,
                 verifying redistribution rights, and assessing evolving legal risks across multiple stages require a
                 level of precision and efficiency that exceeds human capabilities. Addressing this challenge
                 effectively demands AI agents that can systematically trace dataset redistribution, analyze compliance,
                 and identify legal risks. We develop an automated data compliance system called NEXUS and show that AI
                 can perform these tasks with higher accuracy, efficiency, and cost-effectiveness than human experts.
                 Our massive legal analysis of 17,429 unique entities and 8,072 license terms using this approach
                 reveals the discrepancies in legal rights between the original datasets before redistribution and their
                 redistributed subsets, underscoring the necessity of the data lifecycle-aware compliance. For instance,
                 we find that out of 2,852 datasets with commercially viable individual license terms, only 605 (21\%)
                 are legally permissible for commercialization. This work sets a new standard for AI data governance,
                 advocating for a framework that systematically examines the entire lifecycle of dataset redistribution
                 to ensure transparent, legal, and responsible dataset management.",
  cc-author-affiliation = "LG AI Research",
  cc-class     = "legal/copyright, ai/ethics-of-machine-learning, robots.txt, web-crawling",
}

@Article{cc:Havlikova:2025:rightsholders-opt-out-from-gen-ai-training,
  title        = "Technical Challenges of Rightsholders’ Opt-out From {Gen} {AI} Training after {Robert} {Kneschke} v.
                 {LAION}",
  volume       = "16",
  ISSN         = "2190-3387",
  URL          = "https://www.jipitec.eu/jipitec/article/view/422",
  language     = "en",
  number       = "1",
  urldate      = "2025-03-30",
  journal      = "JIPITEC – Journal of Intellectual Property, Information Technology and E-Commerce Law",
  author       = "Havlikova, Stepanka",
  month        = mar,
  year         = "2025",
  keywords     = "Artificial Intelligence, Copyright, Machine-readable, Text and Data Mining, Web Scraping",
  abstract     = "This paper explores the evolving legal landscape surrounding generative AI model training on publicly
                 available - often copyrighted - data, spot-lighting the challenges in the wake of recent decision of
                 German Court in Robert Kneschke v. LAION. On top of already explored implementation of copyright res-
                 ervations by machine-to-machine and human-to-machine communication, this paper explores potential gaps
                 and technical challenges stemming from the text and data mining exception including technical is- sues
                 surrounding Robots.txt as well as data memorisation and regurgitation of verbatim snippets in AI
                 outputs.",
  cc-author-affiliation = "Institute of Law and Technology at Masaryk University, Czech Republic",
  cc-class     = "legal/copyright, robots.txt, text-and-data-mining, nlp/generative-language-models,
                 nlp/large-language-models",
  cc-snippet   = "Common Crawl, non-profit foundation producing and maintaining an open repository of web crawl
                 data,⁹⁴ published its recommended structure of Robots.txt to prevent Common Crawl from crawling a
                 website and recommended implementing “CCBot” to the user-agent line.⁹⁵ According to a study
                 published in 2020, OpenAI’s GPT-3 was trained using data mostly collected from Common Crawl.⁹⁶ On
                 the other hand, Common Crawl is used for a variety of other purposes unrelated to generative artificial
                 intelligence.⁹⁷ [...] Although the Common Crawl Foundation proclaims to comply with Robots.txt and
                 no follow policies of the scraped websites (for these purposes the Common Crawl Foundation even issued
                 its own Robots.txt guidance recommending implementing “CCBot” to the user-agent line¹²³), at the
                 same time Common Crawl’s publicly available Terms of use explicitly limit Common Crawl’s liability
                 for third party IP infringements and explicitly state that Crawled Content may be subject to separate
                 terms of use or terms of service from the owners of such Crawled Content.¹²⁴ These aspects add
                 additional layer of complexity in potential disputes over lawfulness of text and data mining.",
}

@Article{cc:Awad:2025:Generative-AIs-copyright-enigma,
  title        = "Generative {AI}'s Copyright Enigma: {A} Comparative Study of Fair Use and Fair Dealing",
  volume       = "14",
  URL          = "https://www.repository.law.indiana.edu/ipt/vol14/iss2/2",
  shorttitle   = "Generative {AI}'s Copyright Enigma",
  number       = "2",
  journaltitle = "{IP} Theory: Vol. 14: Iss. 2, Article 2",
  author       = "Awad, Taysir",
  date         = "2025-01-01",
  year         = "2025",
  abstract     = "At the dawn of this decade, generative Artificial Intelligence (AI) models were at the apogee of
                 modern science and technology. Their emergence introduced the world to a new paradigm of creativity and
                 innovation, where machines can synthesize art, literature, and design with unprecedented
                 sophistication, blurring the boundaries between human ingenuity and algorithmic computation. These
                 models have the capacity to regenerate Oscar Wilde with the depiction of Ansel Adams, rewrite Harry
                 Potter with William Shakespear’s proverbial tongue, and redesign St. Peter’s Basilica with Gothic
                 arches, Seljuk carved stones, and an Antoni Gaudi roof architecture, relocated in the heart of New York
                 City with the facile of a prompt. Despite this novelty, the copyright industry was perturbed by what
                 they considered a twofold threat to their livelihood. On the one hand, authors feared their works were
                 being exploited, likely reproduced, without adequate remuneration. On the other hand, they feared these
                 models were ominously generating new works, possibly derivative works, that directly compete with the
                 very works that were used in the model’s formation. The matter is currently being adjudicated in
                 courts across the globe.¶ This article examines whether fair use can protect AI companies from
                 copyright liability for both the training process, which allegedly relies on the process of feeding AI
                 datasets (foundation models) predominantly with copyrighted material scraped off the internet for
                 purposes of machine learning; and the outputs that directly compete with the sampled material exploited
                 during the training process. Although several scholars have begun to articulate their own thesis
                 vis-à-vis its legality domestically, this article compares and anticipates how the judiciary in the
                 United States will address these issues as opposed to courts in fair dealing jurisdictions across the
                 globe. The article will expose how the dichotomy between the fair use doctrine and the fair dealing
                 clause imperatively affects the progression of these types of technologies, concluding that fair use is
                 more conductive to development than its foreign counterparts.",
  cc-author-affiliation = "Georgetown University Law Center, USA",
  cc-class     = "legal/copyright, legal/fair-use, nlp/language-model, ai/foundation-model,
                 nlp/multi-modal-language-model, nlp/multimodal-corpora, ai/image-dataset",
}

@Misc{cc:KandpalRaffel:2025:Position-LLM-training-data,
  title        = "Position: The Most Expensive Part of an {LLM} should be its Training Data",
  author       = "Nikhil Kandpal and Colin Raffel",
  year         = "2025",
  eprint       = "2504.12427",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2504.12427",
  abstract     = "Training a state-of-the-art Large Language Model (LLM) is an increasingly expensive endeavor due to
                 growing computational, hardware, energy, and engineering demands. Yet, an often-overlooked (and seldom
                 paid) expense is the human labor behind these models' training data. Every LLM is built on an
                 unfathomable amount of human effort: trillions of carefully written words sourced from books, academic
                 papers, codebases, social media, and more. This position paper aims to assign a monetary value to this
                 labor and argues that the most expensive part of producing an LLM should be the compensation provided
                 to training data producers for their work. To support this position, we study 64 LLMs released between
                 2016 and 2024, estimating what it would cost to pay people to produce their training datasets from
                 scratch. Even under highly conservative estimates of wage rates, the costs of these models' training
                 datasets are 10-1000 times larger than the costs to train the models themselves, representing a
                 significant financial liability for LLM providers. In the face of the massive gap between the value of
                 training data and the lack of compensation for its creation, we highlight and discuss research
                 directions that could enable fairer practices in the future.",
  cc-snippet   = "Unlike other resources needed to produce LLMs, like hardware or energy, most training data has
                 historically been collected for virtually no cost by mining text from the public Internet (Common
                 Crawl). This web-scraped data is foundational to LLMs, particularly in their pre-training phase, where
                 models require vast amounts of text to learn general linguistic and world knowledge. Notably, we are
                 not aware of any compensation being given to the creators of this web text, despite their pivotal role
                 in the success of modern LLMs.",
  cc-author-affiliation = "University of Toronto; Vector Institute",
  cc-class     = "legal/copyright, legal/fair-use, nlp/language-model, ai/foundation-model",
}

@InProceedings{cc:Hanley:2025:International-propaganda-and-influence-networks,
  title        = "Tracking and Identifying International Propaganda and Influence Networks Online",
  author       = "Hanley, Hans WA",
  booktitle    = "Proceedings of the AAAI Conference on Artificial Intelligence",
  volume       = "39",
  number       = "28",
  pages        = "29263--29264",
  year         = "2025",
  URL          = "https://ojs.aaai.org/index.php/AAAI/article/view/35209/37364",
  abstract     = "Misinformation and propaganda undermine trust in institutions, spread falsehoods, and sometimes incite
                 violence. However, recent advancements in transformer-based AI models can help combat the proliferation
                 of disinformation globally and in real time. In this work, I propose and develop a system using these
                 models to scalably identify, track, and analyze the spread of narratives from over 40,000 international
                 news websites. First, by employing novel multilingual Matryoshka embeddings and hierarchical level-wise
                 clustering, my proposed system identifies news stories, topics, and themes across these thousands of
                 news websites. Second, by utilizing multilingual stance detection, my system assesses the biases and
                 factual inconsistencies in news articles, enabling the identification of websites that spread
                 propaganda or misinformation. Finally, through network inference methods, my system uncovers
                 connections among websites disseminating slanted or false content. My approach illustrates how AI can
                 be utilized to mitigate the global spread of harmful misinformation and propaganda.",
  cc-snippet   = "To track the spread of international news narratives, I created and continue to maintain an evolving
                 catalog of popular news-related websites to scrape. To do so, every three months, I use the CommonCrawl
                 website index and the Cloud Domain Intelligence API to compile and refine a list of websites dedicated
                 to “news.” Upon generating this list of news websites, I crawl them daily, collecting each site’s
                 homepage, RSS feed, and the corresponding linked news articles, extracting each page’s article
                 contents.",
  cc-author-affiliation = "Stanford University, USA",
  cc-class     = "misinformation, propaganda, nlp/fake-news-detection, nlp/language-model",
}
