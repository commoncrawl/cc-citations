@InProceedings{cc:RobertsonLagusKajava:2021:covid-19-news-coverage-mood-map,
  title        = "A {COVID}-19 news coverage mood map of {E}urope",
  author       = "Robertson, Frankie and Lagus, Jarkko and Kajava, Kaisla",
  booktitle    = "Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation",
  month        = apr,
  year         = "2021",
  address      = "Online",
  publisher    = "Association for Computational Linguistics",
  URL          = "https://www.aclweb.org/anthology/2021.hackashop-1.15",
  pdf          = "https://www.aclweb.org/anthology/2021.hackashop-1.15.pdf",
  pages        = "110--115",
  abstract     = "We present a COVID-19 news dashboard which visualizes sentiment in pandemic news coverage in different
                 languages across Europe. The dashboard shows analyses for positive/neutral/negative sentiment and moral
                 sentiment for news articles across countries and languages. First we extract news articles from
                 news-crawl. Then we use a pre-trained multilingual BERT model for sentiment analysis of news article
                 headlines and a dictionary and word vectors -based method for moral sentiment analysis of news
                 articles. The resulting dashboard gives a unified overview of news events on COVID-19 news overall
                 sentiment, and the region and language of publication from the period starting from the beginning of
                 January 2020 to the end of January 2021.",
  cc-author-affiliation = "University of Jyväskylä, Finland; University of Helsinki, Finland",
  cc-class     = "nlp/corpus-construction, nlp/sentiment-analysis",
  cc-dataset-used = "CC-NEWS",
  cc-abstract  = "We used the news-please extractor (Hamborg et al.,2017) on news-crawl dumps to obtain a multilingual
                 corpus of European COVID-19 news. News-crawl is a web crawl provided by the CommonCrawl organisation
                 which is updated more frequently and contains only data from news websites
                 [²https://commoncrawl.org/2016/10/news-dataset-available/]. In order to keep the size of the corpus
                 man-ageable and the extraction time reasonable, a list ofinternet domain names of European state
                 broadcasters was first obtained from Wikidata, since filteringat the domain level allows for faster
                 processingof Common Crawl dumps. [...] The resulting corpus contains 468 thousand articles.",
}

@Misc{cc:DodgeSapMarasovicAgnewEtAl:2021:documenting-english-colossal-clean-crawled-corpus,
  title        = "Documenting large webtext corpora: a case study on the Colossal Clean Crawled Corpus",
  author       = "Jesse Dodge and Maarten Sap and Ana Marasovic and William Agnew and Gabriel Ilharco and Dirk
                 Groeneveld and Matt Gardner",
  year         = "2021",
  eprint       = "2104.08758",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2104.08758",
  pdf          = "https://arxiv.org/pdf/2104.08758.pdf",
  abstract     = "Large language models have led to remarkable progress on many NLP tasks, and researchers are turning
                 to ever-larger text corpora to train them. Some of the largest corpora available are made by scraping
                 significant portions of the internet, and are frequently introduced with only minimal documentation. In
                 this work we provide some of the first documentation for the Colossal Clean Crawled Corpus (C4; Raffel
                 et al., 2020), a dataset created by applying a set of filters to a single snapshot of Common Crawl. We
                 begin by investigating where the data came from, and find a significant amount of text from unexpected
                 sources like patents and US military websites. Then we explore the content of the text itself, and find
                 machine-generated text (e.g., from machine translation systems) and evaluation examples from other
                 benchmark NLP datasets. To understand the impact of the filters applied to create this dataset, we
                 evaluate the text that was removed, and show that blocklist filtering disproportionately removes text
                 from and about minority individuals. Finally, we conclude with some recommendations for how to created
                 and document web-scale datasets from a scrape of the internet.",
  cc-author-affiliation = "Paul G. Allen School of Computer Science & Engineering, University of Washington, USA; Allen
                 Institute for Artificial Intelligence, USA",
  cc-class     = "nlp/corpus-construction, nlp/language-model",
  cc-derived-dataset-about = "Tensorflow-C4, Huggingface-Allenai-C4-English",
  cc-dataset-used = "CC-MAIN-2019-18 (WET)",
  cc-abstract  = "C4 is created by taking a snapshot of Common Crawl¹ and applying a number of filters to remove text
                 with the intention of retaining high-quality natural English. We host three different versions of the
                 data: C4.EN.NOCLEAN (C4 with only a language ID filter applied), C4.EN.NOBLOCKLIST (result of all
                 filters except one that discards documents from a list of banned words), and C4.EN (the result of all
                 filters). [...] To facilitate further discussion of the data we host an indexed version of C4 at
                 https://c4-search.apps.allenai.org/, allowing anyone to search it.",
}

@Misc{cc:CaswellKreutzerWangWahabEtAl:2021:audit-web-multilingual-datasets,
  title        = "Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets",
  author       = "Isaac Caswell and Julia Kreutzer and Lisa Wang and Ahsan Wahab and Daan van Esch and Nasanbayar
                 Ulzii-Orshikh and Allahsera Tapo and Nishant Subramani and Artem Sokolov and Claytone Sikasote and
                 Monang Setyawan and Supheakmungkol Sarin and Sokhar Samb and Benoît Sagot and Clara Rivera and Annette
                 Rios and Isabel Papadimitriou and Salomey Osei and Pedro Javier Ortiz Suárez and Iroro Orife and
                 Kelechi Ogueji and Rubungo Andre Niyongabo and Toan Q. Nguyen and Mathias Müller and André Müller
                 and Shamsuddeen Hassan Muhammad and Nanda Muhammad and Ayanda Mnyakeni and Jamshidbek Mirzakhalov and
                 Tapiwanashe Matangira and Colin Leong and Nze Lawson and Sneha Kudugunta and Yacine Jernite and Mathias
                 Jenny and Orhan Firat and Bonaventure F. P. Dossou and Sakhile Dlamini and Nisansa de Silva and Sakine
                 Çabuk Ballı and Stella Biderman and Alessia Battisti and Ahmed Baruwa and Ankur Bapna and Pallavi
                 Baljekar and Israel Abebe Azime and Ayodele Awokoya and Duygu Ataman and Orevaoghene Ahia and
                 Oghenefego Ahia and Sweta Agrawal and Mofetoluwa Adeyemi",
  year         = "2021",
  eprint       = "2103.12028",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2103.12028",
  pdf          = "https://arxiv.org/pdf/2103.12028.pdf",
  abstract     = "With the success of large-scale pre-training and multilingual modeling in Natural Language Processing
                 (NLP), recent years have seen a proliferation of large, web-mined text datasets covering hundreds of
                 languages. However, to date there has been no systematic analysis of the quality of these publicly
                 available datasets, or whether the datasets actually contain content in the languages they claim to
                 represent. In this work, we manually audit the quality of 205 language-specific corpora released with
                 five major public datasets (CCAligned, ParaCrawl, WikiMatrix, OSCAR, mC4), and audit the correctness of
                 language codes in a sixth (JW300). We find that lower-resource corpora have systematic issues: at least
                 15 corpora are completely erroneous, and a significant fraction contains less than 50\% sentences of
                 acceptable quality. Similarly, we find 82 corpora that are mislabeled or use nonstandard/ambiguous
                 language codes. We demonstrate that these issues are easy to detect even for non-speakers of the
                 languages in question, and supplement the human judgements with automatic analyses. Inspired by our
                 analysis, we recommend techniques to evaluate and improve multilingual corpora and discuss the risks
                 that come with low-quality data releases.",
  cc-author-affiliation = "Google Research; Masakhane NLP; Turkic Interlingua; Haverford College; RobotsMali; Intel
                 Labs; University of Zambia; Google; AIMS-AMMI; Inria; University of Zurich; Stanford University; Kwame
                 Nkrumah University of Science and Technology; Sorbonne Université; Niger-Volta LTI; University of
                 Waterloo; University of Electronic Science and Technology of China; University of Notre Dame; Bayero
                 University Kano; University of South Florida; Hugging Face; Jacobs University Bremen; University of
                 Moratuwa; EleutherAI; Obafemi Awolowo University; University of Ibadan; Instadeep; University of
                 Maryland; Defence Space Administration Abuja",
  cc-class     = "nlp/corpus-construction, nlp/web-as-corpus, nlp/parallel-corpus, nlp/low-resource-language",
  cc-derived-dataset-about = "CCAligned-2020, Tensorflow-C4-Multilingual, OSCAR",
  cc-snippet   = "We selected the corpora for their multilinguality and the inclusion of understudied languages in NLP.
                 With the exception of WikiMatrix and Paracrawl, all corpora are derived from CommonCrawl, and
                 distinguish themselves by the choice of filtering methods, LangID and automatic alignment technology.",
}

@Misc{cc:KalaharshaMehtre:2021:detecting-phishing-sites,
  title        = "Detecting Phishing Sites -- An Overview",
  author       = "P. Kalaharsha and B. M. Mehtre",
  year         = "2021",
  eprint       = "2103.12739",
  archiveprefix = "arXiv",
  primaryclass = "cs.CR",
  URL          = "https://arxiv.org/abs/2103.12739",
  pdf          = "https://arxiv.org/pdf/2103.12739.pdf",
  cc-author-affiliation = "Institute for Development and Research in Banking Technology (IDRBT), Hyderabad, Indiab;
                 School of Computer Science and Information Sciences (SCIS), University of Hyderabad, Hyderabad, India",
  cc-class     = "computer-security/internet-security, computer-security/malicious-domain-detection",
  cc-snippet   = "Alexa and Common crawl contains names of the legitimate sites which are likely to be used for phishing
                 [62][63]. [63:http://index.commoncrawl.org]",
  cc-description = "methods and datasets used in Phishing-detection papers",
}

@Misc{cc:XueConstantRobertsKaleEtAl:2021:mT5,
  title        = "m{T5}: {A} massively multilingual pre-trained text-to-text transformer",
  author       = "Linting Xue and Noah Constant and Adam Roberts and Mihir Kale and Rami Al-Rfou and Aditya Siddhant and
                 Aditya Barua and Colin Raffel",
  year         = "2021",
  eprint       = "2010.11934",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2010.11934",
  pdf          = "https://arxiv.org/pdf/2010.11934.pdf",
  cc-author-affiliation = "Google Research",
  cc-class     = "nlp/corpus-creation, nlp/web-as-corpus, nlp/language-model",
  cc-derived-dataset-about = "Tensorflow-C4-Multilingual",
  cc-snippet   = "[...] we introduce mT5, a multilingual variant of T5 that was pre-trained on a new Common Crawl-based
                 dataset covering 101 languages.",
}

@Article{cc:TahirMehmood:2021:corpulyzer,
  title        = "Corpulyzer: {A} Novel Framework for Building Low Resource Language Corpora",
  author       = "Tahir, Bilal and Mehmood, Muhammad Amir",
  journal      = "IEEE Access",
  volume       = "9",
  pages        = "8546--8563",
  year         = "2021",
  publisher    = "IEEE",
  doi          = "10.1109/ACCESS.2021.3049793",
  URL          = "https://ieeexplore.ieee.org/document/9316706",
  pdf          = "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316706",
  cc-author-affiliation = "University of Engineering and Technology, Lahore, Pakistan",
  cc-class     = "nlp/corpus-creation, nlp/web-as-corpus, nlp/low-resource-language",
  cc-snippet   = "Leveraging dataset from Common Crawl Corpus (CCC), first, we prepare a list of seed URLs by filtering
                 the Urdu language webpages. Next, we use Corpulyzer to crawl the World-Wide-Web (WWW) over a period of
                 four years (2016-2020). We build Urdu web corpus “UrduWeb20” that consists of 8.0 million Urdu
                 webpages crawled from 6,590 websites. [...] building a corpus of a low-resource language from CCC is a
                 challenging task due to: i) sampling techniques, ii) filtering of webpages of target languages, and
                 iii) full parsing of CCC. [...] we build upon our previous approach [40] where we developed a dataset
                 consisting of 1.28 million Urdu webpages from CCC 2016 dataset. [...] In general, CCC release meta-data
                 as well as the crawled content where former is lightweight and easier to analyze and latter requires
                 huge bandwidth to download and store the data. As an alternate strategy, we build three datasets using
                 CC released data: i) CC-meta, ii) CC-Urdu-meta, and ii) CC-Urdu-crawl. First, we build CC-meta dataset
                 to explore the impact of URL selection and crawling strategies of Common Crawl in general. This dataset
                 consists of meta-information of 29.1 billion URLs in 11 common crawl releases from September2018 –
                 June2019. This meta-information of each release is available in the form of compressed files (>200GB
                 size) with information of webpage URL, MIME-type, and charset etc [94]. Next, we build CC-Urdu-meta
                 dataset by filtering out Urdu webpages. We note that from August 2018 onward releases [95], CC also
                 provides ISO6 language code of top three languages present in webpages after parsing HTML of the
                 webpage from CLD2.",
}

@Misc{cc:LuccioniViviano:2021:undesirable-content-in-CC-corpus,
  title        = "What's in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus",
  author       = "Alexandra Sasha Luccioni and Joseph D. Viviano",
  year         = "2021",
  eprint       = "2105.02732",
  archiveprefix = "arXiv",
  primaryclass = "cs.CL",
  URL          = "https://arxiv.org/abs/2105.02732",
  pdf          = "https://arxiv.org/pdf/2105.02732.pdf",
  cc-snippet   = "Given its size, both downloading and analyzing the Common Crawl are time-consuming and costly
                 endeavors. The most recent version of the Common Crawl
                 [https://commoncrawl.org/2020/12/nov-dec-2020-crawl-archive-now-available/], dating from
                 November/December 2020, has 2.6 billion web pages in raw text format, saved in ‘shards’ each
                 containing of tens of thousands of pages. Given our hardware constraints, we chose to focus on a subset
                 of the corpus, randomly sampling 1% of the files it contains, roughly amounting toroughly 81 GB of
                 textual content or 5,835,339 webpages in total, which we analyzed in terms of hate speech, adult
                 content, and efficacy of perplexity-based filtering. All code used in these analysis are publicly
                 available¹ [¹https://github.com/josephdviviano/whatsinthebox]. [...] We found that the three
                 approaches compared suggest similar proportions of websites containing hate speech: 5.24% of websites
                 from our sample were flagged by DELIMIT, 4.02% by HateSonar,and 6.38% by the n-gram approach². [²We
                 are conscious of the high false positive rate of n-gram approaches and therefore only consider sites to
                 be flagged if they contain 3 or more n-grams from the list.] Qualitative analysis of a sample of sites
                 flagged by each approach showed that while n-grams picked up on racial slurs, HateSonar picked up on
                 debates about racial supremacy and conspiracy theories. Many of the sites that DELIMIT flagged were
                 adult content with mentions of violent acts towards specific ethnic groups, illustrating the fine line
                 between sexual violence and hate speech. [...] While it can be argued that the Common Crawl corpus is
                 an accurate portrayal of the discourse of modern society – which includes sexual content, hate
                 speech, racial biases, and gender biases – we believe that it is up for debate whether this discourse
                 is the one that we, as a community, want to use to train the models that translate our texts, influence
                 our search results and answer our questions. Notably, the Common Crawl overrepresents those populations
                 that are avid users of the internet: younger, English-speaking individuals from developed countries,
                 [...]",
  cc-author-affiliation = "Université de Montréal, Canada; Mila Québec AI Institute, Canada",
  cc-class     = "ai/ethics-of-machine-learning, nlp/corpus-construction, nlp/text-corpora",
}

@InProceedings{cc:FröbeBevendorffGienappVölskeEtAl:2021:CopyCat,
  author       = "Maik Fröbe and Janek Bevendorff and Lukas Gienapp and Michael Völske and Benno Stein and Martin
                 Potthast and Matthias Hagen",
  booktitle    = "44th International ACM Conference on Research and Development in Information Retrieval (SIGIR 2021)",
  doi          = "10.1145/3404835.3463246",
  publisher    = "ACM",
  site         = "Virtual Event, Canada",
  title        = "{CopyCat: Near-Duplicates within and between the ClueWeb and the Common Crawl}",
  URL          = "https://dl.acm.org/doi/10.1145/3404835.3463246",
  pdf          = "https://webis.de/downloads/publications/papers/froebe_2021.pdf",
  year         = "2021",
  cc-author-affiliation = "Martin-Luther-Universität Halle-Wittenberg, Germany; Bauhaus-Universität Weimar, Germany;
                 Leipzig University, Germany",
  cc-class     = "ir/duplicate-detection",
  cc-dataset-used = "CC-MAIN-2015-11, CC-MAIN-2017-04",
}

@Article{cc:GaoBidermanBlackGoldingEtAl:2021:The-Pile,
  author       = "Leo Gao and Stella Biderman and Sid Black and Laurence Golding and Travis Hoppe and Charles Foster and
                 Jason Phang and Horace He and Anish Thite and Noa Nabeshima and Shawn Presser and Connor Leahy",
  title        = "The Pile: An 800{GB} Dataset of Diverse Text for Language Modeling",
  journal      = "CoRR",
  volume       = "abs/2101.00027",
  year         = "2021",
  URL          = "https://arxiv.org/abs/2101.00027",
  archiveprefix = "arXiv",
  eprint       = "2101.00027",
  pdf          = "https://arxiv.org/pdf/2101.00027.pdf",
  cc-author-affiliation = "EleutherAI",
  cc-class     = "nlp/corpus-construction, nlp/text-corpora, nlp/language-model, nlp/text-corpora/legal-aspects",
  abstract     = "Recent work has demonstrated that increased training dataset diversity improves general cross-domain
                 knowledge and downstream generalization capability for large-scale language models. With this in mind,
                 we present the Pile: an 825 GiB English text corpus targeted at training large-scale language models.
                 The Pile is constructed from 22 diverse high-quality subsets—both existing and newly
                 constructed—many of which derive from academic or professional sources. Our evaluation of the untuned
                 performance of GPT-2 and GPT-3 on the Pile shows that these models struggle on many of its components,
                 such as academic writing. Conversely, models trained on the Pile improve significantly over both Raw CC
                 and CC-100 on all components of the Pile, while improving performance on downstream evaluations.
                 Through an in-depth exploratory analysis, we document potentially concerning aspects of the data for
                 prospective users. We make publicly available the code used in its construction.¹
                 [¹https://pile.eleuther.ai/]",
  cc-snippet   = "The growing need for data in language modeling has caused most existing large-scale language models to
                 turn to the Common Crawl for most or all of their data (Brown et al., 2020; Raffel et al., 2019). While
                 training on the Common Crawl has been effective, recent work has shown that dataset diversity leads to
                 better downstream generalization capability (Rosset, 2019). [...] we also introduce a new filtered
                 subset of Common Crawl,Pile-CC, with improved extraction quality. [...] 2.1 Pile-CC Common Crawl is a
                 collection of website crawls from 2008 onwards, including raw web pages, metadata and text extractions.
                 Due to the raw nature of the dataset, Common Crawl has the advantage of including text from diverse
                 domains, but at the cost of varying quality data. Due to this, use of Common Crawl typically
                 necessitates well-designed extraction and filtering. Our Common Crawl-based dataset, Pile-CC, uses
                 jusText (Endrédy and Novák, 2013) on Web Archive files (raw HTTP responses including page HTML) for
                 extraction, which yields higher quality output than directly using the WET files (extracted
                 plain-text). [...] Surprisingly, raw Common Crawl performs better on the Pile BPB than CC-100, despite
                 losing by a significant margin on LAMBADA and WikiText. We hypothesize that this is due to the
                 perplexity based filtering used in CC-100, where a language model is trained on Wikipedia and all data
                 with a perplexity too high or too low is discarded. This effectively discards any data too similar to
                 or too different from Wikipedia, which severely limits the diversity of the collected data. This result
                 suggests that future work using Common Crawl should take caution with filtering to preserve its
                 diversity.",
  cc-dataset-used = "69 monthly crawls (WARC): CC-MAIN-2013-20 - CC-MAIN-2020-24, cf.
                 https://github.com/leogao2/commoncrawl_downloader/blob/3a7a4a7c33aaee2a45f320f7bc57d0dcd3f3a220/indexes_20200607105929",
  cc-derived-dataset-about = "The-Pile-English",
}

@InProceedings{cc:DerczynskiCiosiciBagliniChristiansenEtAl:2021:Danish-Gigaword-Corpus,
  title        = "The {Danish} Gigaword Corpus",
  author       = "Leon Derczynski and Manuel R. Ciosici and Rebekah Baglini and Morten H. Christiansen and Jacob Aarup
                 Dalsgaard and Riccardo Fusaroli and Peter Juel Henrichsen and Rasmus Hvingelby and Andreas Kirkedal and
                 Alex Speed Kjeldsen and Claus Ladefoged and Finn Årup Nielsen and Jens Madsen and Malte Lau Petersen
                 and Jonathan Hvithamar Rystrøm and Daniel Varab",
  year         = "2021",
  booktitle    = "Proceedings of the 23rd Nordic Conference on Computational Linguistics",
  publisher    = "NEALT",
  pdf          = "http://www.derczynski.com/papers/dagw.pdf",
  URL          = "https://gigaword.dk/",
  cc-author-affiliation = "ITU Copenhagen, Denmark; Aarhus University, Denmark; Danish Language Council, Denmark; TV2
                 Regionerne, Denmark; Karnov Group, Denmark; USC Information Sciences Institute, USA; Alexandra
                 Institute, Denmark; University of Copenhagen, Denmark; Technical University of Denmark; Novo Nordisk,
                 Denmark",
  cc-class     = "nlp/corpus-construction, nlp/text-corpora",
  cc-snippet   = "[...] the Danish section of Common Crawlis plagued by significant amounts of non-Danish content, in
                 part due to the pervasive confusion between Danish and Norwegian Bokmål by highly multilingual
                 language ID classifiers (Haas and Derczynski, 2021). Datasets derived exclusively from Common Crawl
                 also have a bias toward webspeak and content from recent years, leaving models built over them
                 sub-ptimally prepared to process older Danish. Common Crawl’s undirected collection of content often
                 overrepresents some dialects at the expense of other dialects.",
  cc-description = "101 million words of Danish texts from Common Crawl used",
}

@Article{cc:DinklageEllertFischerKurpiczEtAl:2021:wavelet-tree-construction,
  author       = "Dinklage, Patrick and Ellert, Jonas and Fischer, Johannes and Kurpicz, Florian and Löbel, Marvin",
  title        = "Practical Wavelet Tree Construction",
  year         = "2021",
  issue_date   = "July 2021",
  publisher    = "Association for Computing Machinery",
  address      = "New York, NY, USA",
  volume       = "26",
  ISSN         = "1084-6654",
  URL          = "https://doi.org/10.1145/3457197",
  doi          = "10.1145/3457197",
  abstract     = "We present new sequential and parallel algorithms for wavelet tree construction based on a new
                 bottom-up technique. This technique makes use of the structure of the wavelet trees—refining the
                 characters represented in a node of the tree with increasing depth—in an opposite way, by first
                 computing the leaves (most refined), and then propagating this information upwards to the root of the
                 tree. We first describe new sequential algorithms, both in RAM and external memory. Based on these
                 results, we adapt these algorithms to parallel computers, where we address both shared memory and
                 distributed memory settings.In practice, all our algorithms outperform previous ones in both time and
                 memory efficiency, because we can compute all auxiliary information solely based on the information we
                 obtained from computing the leaves. Most of our algorithms are also adapted to the wavelet matrix, a
                 variant that is particularly suited for large alphabets.",
  journal      = "ACM J. Exp. Algorithmics",
  articleno    = "1.8",
  numpages     = "67",
  keywords     = "text indexing, shared memory, external memory, distributed memory, data structures",
  cc-author-affiliation = "TU Dortmund University, Germany",
  cc-class     = "data-structures, text-indexing",
  cc-dataset-used = "CC-MAIN-2019-09 (600 WET files)",
  cc-snippet   = "Common Crawl. The Common Crawl corpus contains websites that are crawled by the Common Crawl Project.
                 We use the WET files, which contain only the textual data of the crawled websites, i. e., no HTML tags.
                 We also removed the meta information added by the Commoncrawl corpus. To be more precise, we used the
                 following WET files:
                 crawl-data/CC-MAIN-2019-09/segments/1550247479101.30/wet/CC-MAIN-20190215183319-20190215205319-#ID.warc.wet,
                 where #ID is in the range from 00000 to 00600. As we only care for the text, we removed the WARC meta
                 information, i. e., each line consisting of WARC/1.0 and the following eight lines. CommonCrawl is the
                 concatenation of all files sorted in ascending order by their ID.",
}

@Article{cc:OlsonNahasChmoulevitchCropperEtAl:2021:naming-unrelated-words-predicts-creativity,
  author       = "Olson, Jay A. and Nahas, Johnny and Chmoulevitch, Denis and Cropper, Simon J. and Webb, Margaret E.",
  title        = "Naming unrelated words predicts creativity",
  volume       = "118",
  number       = "25",
  elocation-id = "e2022340118",
  year         = "2021",
  doi          = "10.1073/pnas.2022340118",
  publisher    = "National Academy of Sciences",
  abstract     = "Many traditional measures of creativity require time-intensive and subjective scoring procedures.
                 Their scores are relative to the specific sample, which makes multicultural or international
                 assessments difficult. Our results show that a shorter and simpler task with automatic and objective
                 scoring may be at least as reliable at measuring verbal creativity. This finding enables assessments
                 across larger and more diverse samples with less bias.Several theories posit that creative people are
                 able to generate more divergent ideas. If this is correct, simply naming unrelated words and then
                 measuring the semantic distance between them could serve as an objective measure of divergent thinking.
                 To test this hypothesis, we asked 8,914 participants to name 10 words that are as different from each
                 other as possible. A computational algorithm then estimated the average semantic distance between the
                 words; related words (e.g., cat and dog) have shorter distances than unrelated ones (e.g., cat and
                 thimble). We predicted that people producing greater semantic distances would also score higher on
                 traditional creativity measures. In Study 1, we found moderate to strong correlations between semantic
                 distance and two widely used creativity measures (the Alternative Uses Task and the
                 Bridge-the-Associative-Gap Task). In Study 2, with participants from 98 countries, semantic distances
                 varied only slightly by basic demographic variables. There was also a positive correlation between
                 semantic distance and performance on a range of problems known to predict creativity. Overall, semantic
                 distance correlated at least as strongly with established creativity measures as those measures did
                 with each other. Naming unrelated words in what we call the Divergent Association Task can thus serve
                 as a brief, reliable, and objective measure of divergent thinking.The data and algorithm code have been
                 deposited in the Open Science Framework (https://osf.io/vjazn/).",
  ISSN         = "0027-8424",
  URL          = "https://www.pnas.org/content/118/25/e2022340118",
  pdf          = "https://www.pnas.org/content/118/25/e2022340118.full.pdf",
  journal      = "Proceedings of the National Academy of Sciences",
  cc-author-affiliation = "Department of Psychology, Harvard University, Cambridge, MA, USA; Department of Psychology,
                 McGill University, Montreal, QC, Canada; Melbourne School of Psychological Sciences, University of
                 Melbourne, Australia",
  cc-class     = "psychology/creativity, psychology/computational-scoring, nlp/word-embeddings",
  cc-derived-dataset-used = "GloVe-word-embeddings",
  cc-snippet   = "We chose the GloVe algorithm and the Common Crawl corpus [...]",
}

@Article{cc:AghajanyanOkhonkoLewisJoshiEtAl:2021:HTLM,
  title        = "{HTLM}: Hyper-Text Pre-Training and Prompting of Language Models",
  author       = "Aghajanyan, Armen and Okhonko, Dmytro and Lewis, Mike and Joshi, Mandar and Xu, Hu and Ghosh, Gargi
                 and Zettlemoyer, Luke",
  year         = "2021",
  URL          = "https://arxiv.org/abs/2107.06955",
  pdf          = "https://arxiv.org/pdf/2107.06955.pdf",
  abstract     = "We introduce HTLM, a hyper-text language model trained on a large-scale web crawl. Modeling hyper-text
                 has a number of advan- tages: (1) it is easily gathered at scale, (2) it provides rich document-level
                 and end-task- adjacent supervision (e.g. class and id at- tributes often encode document category
                 information), and (3) it allows for new structured prompting that follows the established seman- tics
                 of HTML (e.g. to do zero-shot summarization by infilling <title> tags for a webpage that contains the
                 input text). We show that pretraining with a BART-style denoising loss directly on simplified HTML
                 provides highly effective transfer for a wide range of end tasks and supervision levels. HTLM matches
                 or exceeds the performance of comparably sized text-only LMs for zero-shot prompting and fine-tuning
                 for classification benchmarks, while also setting new state-of-the-art performance levels for zero-shot
                 summarization. We also find that hyper-text prompts provide more value to HTLM, in terms of data
                 efficiency, than plain text prompts do for existing LMs, and that HTLM is highly effective at auto-
                 prompting itself, by simply generating the most likely hypertext formatting for any available training
                 data. We will release all code and models to support future HTLM research.",
  cc-author-affiliation = "Facebook AI; University of Washington, USA",
  cc-class     = "nlp/corpus-construction, nlp/text-corpora, nlp/transformer-language-model",
  cc-snippet   = "Our HyperTextLanguageModel (HTLM) is trained on 23TB of simplified HTML which we automatically extract
                 from common crawl dumps [...]",
}

@InProceedings{cc:AbadjiOrtiz-SuárezRomarySagot:2021:Ungoliant,
  title        = "Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus",
  author       = "Abadji, Julien and Ortiz Suárez, Pedro Javier and Romary, Laurent and Sagot, Benoît",
  booktitle    = "Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick,
                 12 July 2021 (Online-Event)",
  pages        = "1--9",
  year         = "2021",
  organization = "Leibniz-Institut für Deutsche Sprache",
  abstract     = "Since the introduction of large language models in Natural Language Processing, large raw corpora have
                 played a crucial role in Computational Linguistics. However, most of these large raw corpora are either
                 available only for English or not available to the general public due to copyright issues.
                 Nevertheless, there are some examples of freely available multilingual corpora for training Deep
                 Learning NLP models, such as the OSCAR and Paracrawl corpora. However, they have quality issues,
                 especially for low-resource languages. Moreover, recreating or updating these corpora is very complex.
                 In this work, we try to reproduce and improve the goclassy pipeline used to create the OSCAR corpus. We
                 propose a new pipeline that is faster, modular, parameterizable, and well documented. We use it to
                 create a corpus similar to OSCAR but larger and based on recent data. Also, unlike OSCAR, the metadata
                 information is at the document level. We release our pipeline under an open source license and publish
                 the corpus under a research-only license.",
  URL          = "https://ids-pub.bsz-bw.de/frontdoor/deliver/index/docId/10468/file/Abadji_Suarez_Romary_Ungoliant_2021.pdf",
  cc-author-affiliation = "Inria, Paris, France; Sorbonne Université, Paris, France",
  cc-class     = "nlp/corpus-construction, nlp/text-corpora",
}

@Misc{cc:GrossmanZonszein:2021:voted-in-standing-out,
  title        = "Voted In, Standing Out: Public Response to Immigrants' Political Accession",
  URL          = "https://osf.io/xd4wk/",
  doi          = "10.31219/osf.io/xd4wk",
  publisher    = "OSF Preprints",
  author       = "Grossman, Guy and Zonszein, Stephanie",
  year         = "2021",
  abstract     = "In a context of nativism and poor representation of immigrant-origin ethnic minori- ties, what is the
                 reaction of the host society when immigrants succeed at integration in political institutions? Building
                 on threat theory—which links minorities’ political power to hostility against minoritized
                 groups—we argue that when they win political office, immigrants pose a threat to natives’ dominant
                 position. This in turn triggers a hostile reaction from a violent-prone fringe, the mass public and the
                 elites. We test these dynamics across the last four UK general elections, using hate crime police
                 records, public opinion data, and text data from over 500,000 news articles from 350 na- tional and
                 local newspapers. We identify the public’s hostile reactions with a regression discontinuity design
                 that leverages close election results between minority-immigrant and dominant group candidates. Our
                 findings suggest a public backlash against ethnic minority immigrants’ integration into majority
                 settings.",
  cc-author-affiliation = "University of Pennsylvania, USA",
  cc-class     = "political science; sociology; ethnic minorities",
  cc-dataset-used = "CC-MAIN-2020-16",
  cc-class     = "political science, sociology, political integration of immigrants",
  cc-snippet   = "News articles were extracted from Common Crawl, ethnic background of candidates is constructed by the
                 authors, and constituency characteristics from 2001 and 2011 UK Decennial Census. [...] Then, to obtain
                 the articles published by each of these newspapers, we looked up the URLs in Common Crawl (an open
                 repository of web crawl data containing a snapshot of every web page at the moment of the crawl).
                 Particularly in the Index for 2020-16 crawl, the most recent crawl at that moment. We retrieved the
                 WARC (Web ARChive format) records for each crawled page from the newspaper, and extracted the pages’
                 HTML. From the HTML, we extracted the text, title, and byline using the Python package readabiliPy; the
                 publication date using the Python library htmldate; the location by tokenizing the article with
                 CoreNLP, and looking for tokens which match place names in the Index of Place Names in Great Britain,
                 and mapping to the corresponding constituency. Figure D.1 presents the geographical coverage of all
                 extracted articles across constituencies.¶ [...] 4.3 Media tone toward migrant groups¶ Data We use
                 data from over 500,000 articles from 350 national, regional and local UK newspapers, covering the
                 general elections from 2010–2019.⁸ This data is from Common Crawl, which is an open repository of
                 web crawl data. We assume that an article refers to a candidate’s ethnic group when three conditions
                 are met: 1) the publication date is on election day and up to 10 months after each general election⁹,
                 2) the article contains mentions of terms referring to the candidate’s country or nationality of
                 origin, which are extracted with the named entity annotator of CoreNLP and 3) such mentions co-occur in
                 the article with a mention referring to the candidate’s constituency. The constituency is extracted
                 by tokenizing the article with CoreNLP and looking for tokens which match place names in the Index of
                 Place Names in Great Britain, and mapping to the corresponding constituency. Overall, this data
                 includes almost 150,000 mentions from 156 newspapers that meet these three conditions about the
                 candidates’ group. [...] D Newspaper data, computation of media tone measures and validation of key
                 elements Newspaper data We construct the dataset of newspaper articles using the following steps. To
                 determine a comprehensive list of UK newspapers, we first identified a list of seed categories on
                 Wikipedia (WP) (e.g. ’Category:Newspapers_published_in_England’), we took the recursive items of
                 those categories (e.g. ’Category:Newspapers_published_in_England’ >
                 ’Category:Newspapers_published_in_London’), we used WP article properties to filter out articles
                 about non-newspapers (e.g. people, books), and we extracted the newspaper URLs from the WP Infobox
                 using the Python package wptools. With this process we identified a list of UK newspapers URLs
                 containing 337 newspapers in total. Then, to obtain the articles published by each of these newspapers,
                 we looked up the URLs in Common Crawl (an open repository of web crawl data containing a snapshot of
                 every web page at the moment of the crawl). Particularly in the Index for 2020-16 crawl, the most
                 recent crawl at that moment. We retrieved the WARC (Web ARChive format) records for each crawled page
                 from the newspaper, and extracted the pages’ HTML. From the HTML, we extracted the text, title, and
                 byline using the Python package readabiliPy; the publication date using the Python library htmldate;
                 the location by tokenizing the article with CoreNLP, and looking for tokens which match place names in
                 the Index of Place Names in Great Britain, and mapping to the corresponding constituency. Figure D.1
                 presents the geographical coverage of all extracted articles across constituencies.",
}

@Misc{cc:NgoAraújoHuiFrosst:2021:no-news-is-good-news,
  title        = "No News is Good News: {A} Critique of the One Billion Word Benchmark",
  author       = "Helen Ngo and João G. M. Araújo and Jeffrey Hui and Nicholas Frosst",
  year         = "2021",
  pdf          = "https://arxiv.org/pdf/2110.12609.pdf",
  URL          = "https://arxiv.org/abs/2110.12609",
  abstract     = "The One Billion Word Benchmark is a dataset derived from the WMT 2011 News Crawl, commonly used to
                 measure language modeling ability in natural language processing. We train models solely on Common
                 Crawl web scrapes partitioned by year, and demonstrate that they perform worse on this task over time
                 due to distributional shift. Analysis of this corpus reveals that it contains several examples of
                 harmful text, as well as outdated references to current events. We suggest that the temporal nature of
                 news and its distribution shift over time makes it poorly suited for measuring language modeling
                 ability, and discuss potential impact and considerations for researchers building language models and
                 evaluation datasets.",
  cc-author-affiliation = "Cohere, Toronto, Canada",
  cc-class     = "nlp/language-model, nlp/language-model/perplexity",
  cc-snippet   = "Common Crawl is a repository of web scrapes of the internet updated annually and is often used as a
                 key data source for language models built on the open web [8, 2, 1]. We train benchmark models on three
                 distinct datasets created by selecting data sampled from different years of Common Crawl: 2013 (the
                 year which lm1b was released), 2016, and 2020. [...] Models which are trained on datasets temporally
                 further removed from the lm1b corpus source (i.e. WMT 2011 News Crawl dataset) exhibit higher
                 perplexity than those trained on datasets which are temporally closer.",
}

@Misc{cc:Gao:2021:quality-filtering-of-text-data,
  title        = "An Empirical Exploration in Quality Filtering of Text Data",
  author       = "Leo Gao",
  year         = "2021",
  pdf          = "https://arxiv.org/pdf/2109.00698.pdf",
  URL          = "https://arxiv.org/abs/2109.00698",
  abstract     = "While conventional wisdom suggests that more aggressively filtering data from low-quality sources like
                 Common Crawl always monotonically improves the quality of training data, we find that aggressive
                 filtering can in fact lead to a decrease in model quality on a wide array of downstream tasks for a
                 GPT-like language model. We speculate that this is because optimizing sufficiently strongly for a proxy
                 metric harms performance on the true objective, suggesting a need for more robust filtering objectives
                 when attempting to filter more aggressively. We hope this work leads to detailed analysis of the
                 effects of dataset filtering design choices on downstream model performance in future work.",
  cc-author-affiliation = "EleutherAI",
  cc-class     = "nlp/language-model, nlp/corpus-construction",
  cc-snippet   = "The recent proliferation of ever larger language models has led to increasing demands on training data
                 (Radford et al., 2018, 2019; Gokaslan and Cohen, 2019; Rosset, 2019; Shoeybi et al., 2019; Devlin et
                 al., 2019; Liu et al., 2019; Raffel et al., 2020; Brown et al., 2020; Zeng et al., 2021). This data is
                 increasingly derived from internet corpora like Common Crawl (Radford et al., 2019; Ortiz Suárez et
                 al., 2019; Wenzek et al., 2020; Conneau et al., 2020; Brown et al., 2020; Gao et al., 2020; Raffel et
                 al., 2020). However, the quality of raw Common Crawl data is often insufficient to be directly used. To
                 combat this, many existing works use some kind of proxy for quality, like a classifier between known
                 high quality data and low quality data (Brown et al., 2020; Gao et al., 2020; Zeng et al., 2021),
                 handcrafted heuristics (Yang et al., 2020; Raffel et al., 2020), or keeping only documents with
                 perplexity scores that fall in some middle quantile of an existing language model (Wenzek et al.,
                 2020). Brown et al. (2020) in particular filter extremely aggres- sively using their classifier,
                 discarding about 98.7% of their data. Previous work has shown that models trained on heuristic-filtered
                 datasets perform better on downstream tasks (Raffel et al., 2020). However, Gao et al. (2020) show that
                 a perplexity-filtered CC- derived dataset actually performs worse than unfiltered CC on certain tasks.
                 [...] We hypothesize that this decline in performance is because of misalignment between the classifier
                 objective, intended to be a proxy for quality, and actual document quality. For instance, a classifier
                 to distinguish WebText2 from Common Crawl, as in GPT-3, would also exclude domains of text data not
                 found as often in WebText2.",
}
